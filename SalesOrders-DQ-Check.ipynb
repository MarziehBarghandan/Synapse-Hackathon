{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys\r\n",
        "import datetime, time\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "from pyspark import SparkContext, SparkConf\r\n",
        "from pyspark.sql import functions as F\r\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\r\n",
        "\r\n",
        "\r\n",
        "def get_null_perc(spark, df, null_cols):\r\n",
        "    \"\"\" Get null/empty percentage for columns\r\n",
        "\r\n",
        "    Args:\r\n",
        "        spark (Spark): SparkSession object\r\n",
        "        df (DataFrame): dataframe to perform null/empty analysis on\r\n",
        "        null_cols (List): list of columns that need to be considered for analysis\r\n",
        "\r\n",
        "    Returns:\r\n",
        "        DataFrame: dataframe with null check analysis\r\n",
        "    \"\"\"\r\n",
        "    schema = StructType([ \\\r\n",
        "        StructField(\"Column\",StringType(),True), \\\r\n",
        "        StructField(\"NullPercentage\",StringType(),True)\r\n",
        "      ])\r\n",
        "    emptyRDD = spark.sparkContext.emptyRDD()\r\n",
        "    resultdf = spark.createDataFrame(emptyRDD, schema=schema)\r\n",
        "    \r\n",
        "    for x in null_cols:\r\n",
        "    \tdf_null_count = df.select(F.col(x)).filter(F.col(x).isNull() | (F.col(x) == '')).count()\r\n",
        "    \tdf_null = spark.createDataFrame([[x, str(df_null_count*100.0/df.count()) + '%' ]],schema=schema)\r\n",
        "    \tresultdf = resultdf.union(df_null)\r\n",
        "\r\n",
        "    return resultdf\r\n",
        "\r\n",
        "def get_summary_numeric(df, numeric_cols):\r\n",
        "    \"\"\" Get Summary for numeric columns\r\n",
        "\r\n",
        "    Args:\r\n",
        "        df (DataFrame): dataframe to perform analysis on\r\n",
        "        numeric_cols (List): list of columns that need to be considered for analysis\r\n",
        "\r\n",
        "    Returns:\r\n",
        "        DataFrame: dataframe with summary analysis\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    return df.select(numeric_cols).summary()\r\n",
        "\r\n",
        "def get_distinct_counts(spark, df, aggregate_cols):\r\n",
        "    \"\"\" Get distinct count for columns\r\n",
        "\r\n",
        "    Args:\r\n",
        "        spark (Spark): SparkSession object\r\n",
        "        df (DataFrame): dataframe to perform distinct count analysis on\r\n",
        "        aggregate_cols (List): list of columns that need to be considered for analysis\r\n",
        "\r\n",
        "    Returns:\r\n",
        "        DataFrame: dataframe with distinct count analysis\r\n",
        "    \"\"\"\r\n",
        "    schema = StructType([ \\\r\n",
        "        StructField(\"Column\",StringType(),True), \\\r\n",
        "        StructField(\"DistinctCount\",StringType(),True)\r\n",
        "      ])\r\n",
        "    \r\n",
        "    emptyRDD = spark.sparkContext.emptyRDD()\r\n",
        "    resultdf = spark.createDataFrame(emptyRDD, schema=schema)\r\n",
        "    \r\n",
        "    for x in aggregate_cols:\r\n",
        "    \tdf_distinct_count = df.select(F.col(x)).distinct().count()\r\n",
        "    \tdf_distinct = spark.createDataFrame([[x, str(df_distinct_count)]],schema=schema)\r\n",
        "    \tresultdf = resultdf.union(df_distinct)\r\n",
        "\r\n",
        "    return resultdf\r\n",
        "\r\n",
        "def get_distribution_counts(spark, df, aggregate_cols):\r\n",
        "    \"\"\" Get Distribution Counts for columns\r\n",
        "\r\n",
        "    Args:\r\n",
        "        spark (Spark): SparkSession object\r\n",
        "        df (DataFrame): dataframe to perform null/empty analysis on\r\n",
        "        aggregate_cols (List): list of columns that need to be considered for analysis\r\n",
        "\r\n",
        "    Returns:\r\n",
        "        Array: Array of objects with dataframes\r\n",
        "    \"\"\"\r\n",
        "    result = []\r\n",
        "    for i in aggregate_cols:\r\n",
        "    \tresult.append(df.groupby(F.col(i)).count().sort(F.col(\"count\").desc()))\r\n",
        "    ###\r\n",
        "    \r\n",
        "    return result\r\n",
        "\r\n",
        "def get_mismatch_perc(spark, df, data_quality_cols_regex):\r\n",
        "    \"\"\" Get Mismatch Percentage for columns\r\n",
        "\r\n",
        "    Args:\r\n",
        "        spark (Spark): SparkSession object\r\n",
        "        df (DataFrame): dataframe to perform null/empty analysis on\r\n",
        "        data_quality_cols_regex (Dictionary): Dictionary of columns/regex-expression for data quality analysis\r\n",
        "\r\n",
        "    Returns:\r\n",
        "        DataFrame: DataFrame with data quality analysis\r\n",
        "    \"\"\"\r\n",
        "    schema = StructType([ \\\r\n",
        "        StructField(\"Column\",StringType(),True), \\\r\n",
        "        StructField(\"MismatchPercentage\",StringType(),True)\r\n",
        "      ])\r\n",
        "    \r\n",
        "    emptyRDD = spark.sparkContext.emptyRDD()\r\n",
        "    resultdf = spark.createDataFrame(emptyRDD, schema=schema)\r\n",
        "    \r\n",
        "    \r\n",
        "    for key, value in data_quality_cols_regex.items():\r\n",
        "    \tdf_regex_not_like_count = df.select(F.col(key)).filter(~F.col(key).rlike(value)).count()\r\n",
        "    \tdf_regex_not_like = spark.createDataFrame([[key, str(df_regex_not_like_count*100.0/df.count()) + '%']],schema=schema)\r\n",
        "    \tresultdf = resultdf.union(df_regex_not_like)\r\n",
        "    \r\n",
        "    return resultdf"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SparkPool01",
              "session_id": 12,
              "statement_id": 1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-06-01T16:31:58.0471038Z",
              "session_start_time": "2022-06-01T16:31:58.1014862Z",
              "execution_start_time": "2022-06-01T16:32:51.5008677Z",
              "execution_finish_time": "2022-06-01T16:32:51.9560072Z"
            },
            "text/plain": "StatementMeta(SparkPool01, 12, 1, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tables for data quality checks \r\n",
        "\r\n",
        "df = spark.read.load('abfss://wwi-02@asadatalakemarziadmin.dfs.core.windows.net/customer-info/customerinfo.csv', format='csv'\r\n",
        "## If header exists uncomment line below\r\n",
        ", header=True\r\n",
        ")\r\n",
        "display(df.limit(10))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SparkPool01",
              "session_id": 12,
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-06-01T16:35:38.2375169Z",
              "session_start_time": null,
              "execution_start_time": "2022-06-01T16:35:38.6732106Z",
              "execution_finish_time": "2022-06-01T16:35:53.1245678Z"
            },
            "text/plain": "StatementMeta(SparkPool01, 12, 3, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.widget-view+json": {
              "widget_id": "c70c775b-f7eb-4768-87de-3b3bc96411f3",
              "widget_type": "Synapse.DataFrame"
            },
            "text/plain": "SynapseWidget(Synapse.DataFrame, c70c775b-f7eb-4768-87de-3b3bc96411f3)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "microsoft": {},
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType([\r\n",
        "\t\t \tStructField(name='Gender', dataType=StringType(), nullable=True),\r\n",
        "\t\t \tStructField(name='Email', dataType=StringType(), nullable=True),\r\n",
        "            StructField(name='Phone', dataType=IntegerType(), nullable=True)\r\n",
        "\t\t \t])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SparkPool01",
              "session_id": 12,
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-06-01T16:36:42.5957669Z",
              "session_start_time": null,
              "execution_start_time": "2022-06-01T16:36:42.9967391Z",
              "execution_finish_time": "2022-06-01T16:36:43.4761298Z"
            },
            "text/plain": "StatementMeta(SparkPool01, 12, 6, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a master schema of all columns name and type. below is an example for Sales.Orders Table\r\n",
        "schema = StructType([\r\n",
        "\t\t \tStructField(name='OrderID', dataType=IntegerType(), nullable=False),\r\n",
        "\t\t \tStructField(name='CustomerID', dataType=IntegerType(), nullable=False),\r\n",
        "\t\t \tStructField(name='SalespersonPersonID', dataType=IntegerType(), nullable=True),\r\n",
        "            StructField(name='PickedByPersonID', dataType=IntegerType(), nullable=True),\r\n",
        "            StructField(name='ContactPersonID', dataType=IntegerType(), nullable=True),\r\n",
        "            StructField(name='BackorderOrderID', dataType=IntegerType(), nullable=True),\r\n",
        "\t\t \tStructField(name='OrderDate', dataType=DateType(), nullable=False),\r\n",
        "\t\t \tStructField(name='ExpectedDeliveryDate', dataType=DateType(), nullable=True),\r\n",
        "\t\t \tStructField(name='CustomerPurchaseOrderNumber', dataType=StringType(), nullable=True),\r\n",
        "            StructField(name='IsUndersupplyBackordered', dataType=StringType(), nullable=True),\r\n",
        "            StructField(name='Comments', dataType=StringType(), nullable=True),\r\n",
        "\t\t \tStructField(name='DeliveryInstructions', dataType=StringType(), nullable=True),\r\n",
        "            StructField(name='InternalComments', dataType=StringType(), nullable=True),\r\n",
        "\t\t \tStructField(name='PickingCompletedWhen', dataType=TimestampType(), nullable=True),\r\n",
        "\t\t \tStructField(name='LastEditedBy', dataType=IntegerType(), nullable=True),\r\n",
        "\t\t \tStructField(name='LastEditedWhen', dataType=TimestampType(), nullable=True)\r\n",
        "\t\t \t])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "null_cols = ['Email']\r\n",
        "numeric_cols = ['Phone']\r\n",
        "aggregate_cols = ['Email']\r\n",
        "data_quality_cols_regex = {'age': '^[0-99]{1,2}$', 'first_name': '^[a-zA-Z]*$', 'gender': '^M(ale)?$|^F(emale)?$', 'Email':'/^([a-zA-Z0-9._%-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,6})*$/'}\r\n",
        "result_limit = 10"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SparkPool01",
              "session_id": 12,
              "statement_id": 11,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-06-01T16:39:05.7532549Z",
              "session_start_time": null,
              "execution_start_time": "2022-06-01T16:39:06.1475187Z",
              "execution_finish_time": "2022-06-01T16:39:06.5738363Z"
            },
            "text/plain": "StatementMeta(SparkPool01, 12, 11, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "null_cols = ['OrderID','CustomerID','OrderDate']\r\n",
        "numeric_cols = ['OrderID', 'CustomerID','SalespersonPersonID','PickedByPersonID','ContactPersonID','BackorderOrderID']\r\n",
        "aggregate_cols = ['OrderID',]\r\n",
        "#data_quality_cols_regex = {'age': '^[0-99]{1,2}$', 'first_name': '^[a-zA-Z]*$', 'gender': '^M(ale)?$|^F(emale)?$', 'Email':'/^([a-zA-Z0-9._%-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,6})*$/'}\r\n",
        "data_quality_cols_regex = {'Gender': '^M(ale)?$|^F(emale)?$', 'Email':'/^([a-zA-Z0-9._%-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,6})*$/'}\r\n",
        "result_limit = 10"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SparkPool01",
              "session_id": 12,
              "statement_id": 15,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-06-01T16:40:35.0828718Z",
              "session_start_time": null,
              "execution_start_time": "2022-06-01T16:40:35.5081869Z",
              "execution_finish_time": "2022-06-01T16:40:35.9546729Z"
            },
            "text/plain": "StatementMeta(SparkPool01, 12, 15, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 1. NULL Checks\r\n",
        "resultdf = get_null_perc(spark, df, null_cols)\r\n",
        "print(\"NULL/Empty Percentage for Columns\")\r\n",
        "resultdf.show(result_limit, False)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SparkPool01",
              "session_id": 12,
              "statement_id": 8,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-06-01T16:38:11.8234227Z",
              "session_start_time": null,
              "execution_start_time": "2022-06-01T16:38:12.2025672Z",
              "execution_finish_time": "2022-06-01T16:38:15.2464519Z"
            },
            "text/plain": "StatementMeta(SparkPool01, 12, 8, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NULL/Empty Percentage for Columns\n+------+--------------+\n|Column|NullPercentage|\n+------+--------------+\n|Email |0.0%          |\n+------+--------------+\n\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###2. Summary, Average, Standard Deviation, Percentiles for Numeric Columns\r\n",
        "resultdf = get_summary_numeric(df, numeric_cols)\r\n",
        "print(\"Summary for Numeric Columns\")\r\n",
        "resultdf.show(result_limit, False)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SparkPool01",
              "session_id": 12,
              "statement_id": 9,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-06-01T16:38:18.6967778Z",
              "session_start_time": null,
              "execution_start_time": "2022-06-01T16:38:19.2093303Z",
              "execution_finish_time": "2022-06-01T16:38:20.3992771Z"
            },
            "text/plain": "StatementMeta(SparkPool01, 12, 9, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary for Numeric Columns\n+-------+-------------------+\n|summary|Phone              |\n+-------+-------------------+\n|count  |110                |\n|mean   |null               |\n|stddev |null               |\n|min    |(218) 273-8495 x198|\n|25%    |null               |\n|50%    |null               |\n|75%    |null               |\n|max    |995-366-5180       |\n+-------+-------------------+\n\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###3. Distinct Count\r\n",
        "print(\"Distinct Counts for Aggregate Columns\")\r\n",
        "resultdf = get_distinct_counts(spark, df, aggregate_cols)\r\n",
        "resultdf.show(result_limit, False)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SparkPool01",
              "session_id": 12,
              "statement_id": 12,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-06-01T16:39:12.5280937Z",
              "session_start_time": null,
              "execution_start_time": "2022-06-01T16:39:13.0193722Z",
              "execution_finish_time": "2022-06-01T16:39:17.5367867Z"
            },
            "text/plain": "StatementMeta(SparkPool01, 12, 12, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distinct Counts for Aggregate Columns\n+------+-------------+\n|Column|DistinctCount|\n+------+-------------+\n|Email |110          |\n+------+-------------+\n\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "###4. Distribution Count\r\n",
        "print(\"Distribution Count for Aggregate Columns\")\r\n",
        "result = get_distribution_counts(spark, df, aggregate_cols)\r\n",
        "for i in result:\r\n",
        "\tprint(\"======== Distribution for - \" + i.columns[0] + \" ========\")\r\n",
        "\ti.show(result_limit, False)\r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SparkPool01",
              "session_id": 12,
              "statement_id": 13,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-06-01T16:39:20.4317059Z",
              "session_start_time": null,
              "execution_start_time": "2022-06-01T16:39:20.8678043Z",
              "execution_finish_time": "2022-06-01T16:39:23.8209205Z"
            },
            "text/plain": "StatementMeta(SparkPool01, 12, 13, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution Count for Aggregate Columns\n======== Distribution for - Email ========\n+--------------------------------------+-----+\n|Email                                 |count|\n+--------------------------------------+-----+\n|Noel55@adventureworks.com             |1    |\n|Frank_Weissnat@adventureworks.com     |1    |\n|Maria23@adventureworks.com            |1    |\n|Alton_Vandervort@adventureworks.com   |1    |\n|Damon.Price@adventureworks.com        |1    |\n|Brian_Stark95@adventureworks.com      |1    |\n|Terrell54@adventureworks.com          |1    |\n|Alicia_Nicolas78@adventureworks.com   |1    |\n|Charles_Breitenberg@adventureworks.com|1    |\n|Alvin_Volkman36@adventureworks.com    |1    |\n+--------------------------------------+-----+\nonly showing top 10 rows\n\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###5. Data Quality\r\n",
        "print(\"Data Quality Issue Percentage for Columns\")\r\n",
        "resultdf = get_mismatch_perc(spark, df, data_quality_cols_regex)\r\n",
        "resultdf.show(result_limit, False)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "SparkPool01",
              "session_id": 12,
              "statement_id": 16,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-06-01T16:40:43.2757492Z",
              "session_start_time": null,
              "execution_start_time": "2022-06-01T16:40:43.7067937Z",
              "execution_finish_time": "2022-06-01T16:40:46.9621289Z"
            },
            "text/plain": "StatementMeta(SparkPool01, 12, 16, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Quality Issue Percentage for Columns\n+------+------------------+\n|Column|MismatchPercentage|\n+------+------------------+\n|Gender|0.0%              |\n|Email |100.0%            |\n+------+------------------+\n\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {
        "c70c775b-f7eb-4768-87de-3b3bc96411f3": {
          "type": "Synapse.DataFrame",
          "sync_state": {
            "table": {
              "rows": [
                {
                  "0": "Jason.Green",
                  "1": "Male",
                  "2": "1-364-410-6690 x08562",
                  "3": "Jason.Green@adventureworks.com",
                  "4": "9777-4287-8862-7386"
                },
                {
                  "0": "Ben_Dickens",
                  "1": "Male",
                  "2": "551-530-7354 x0506",
                  "3": "Ben_Dickens@adventureworks.com",
                  "4": "2992-5468-4860-3593"
                },
                {
                  "0": "Alton_Vandervort",
                  "1": "Male",
                  "2": "811-714-3148",
                  "3": "Alton_Vandervort@adventureworks.com",
                  "4": "2235-1309-9262-3979"
                },
                {
                  "0": "Theresa16",
                  "1": "Female",
                  "2": "826-960-1591 x58508",
                  "3": "Theresa16@adventureworks.com",
                  "4": "4128-2405-5087-4621"
                },
                {
                  "0": "Robert_Jerde95",
                  "1": "Male",
                  "2": "(888) 258-7303 x20068",
                  "3": "Robert_Jerde95@adventureworks.com",
                  "4": "4347-5516-7396-9369"
                },
                {
                  "0": "Jana.Schmeler",
                  "1": "Female",
                  "2": "386-275-8812 x4018",
                  "3": "Jana.Schmeler@adventureworks.com",
                  "4": "2146-3328-9686-9169"
                },
                {
                  "0": "Nathaniel_Botsford51",
                  "1": "Male",
                  "2": "(502) 878-3300",
                  "3": "Nathaniel_Botsford51@adventureworks.com",
                  "4": "3779-7612-8624-1689"
                },
                {
                  "0": "Alison.Towne24",
                  "1": "Female",
                  "2": "558-321-4825",
                  "3": "Alison.Towne24@adventureworks.com",
                  "4": "2843-2778-7439-4285"
                },
                {
                  "0": "Miriam15",
                  "1": "Female",
                  "2": "1-275-627-5013",
                  "3": "Miriam15@adventureworks.com",
                  "4": "5569-4082-4834-9146"
                },
                {
                  "0": "George26",
                  "1": "Male",
                  "2": "934-857-5803 x6808",
                  "3": "George26@adventureworks.com",
                  "4": "3675-6910-2334-5648"
                }
              ],
              "schema": [
                {
                  "key": "0",
                  "name": "UserName",
                  "type": "string"
                },
                {
                  "key": "1",
                  "name": "Gender",
                  "type": "string"
                },
                {
                  "key": "2",
                  "name": "Phone",
                  "type": "string"
                },
                {
                  "key": "3",
                  "name": "Email",
                  "type": "string"
                },
                {
                  "key": "4",
                  "name": "CreditCard",
                  "type": "string"
                }
              ],
              "truncated": false
            },
            "isSummary": false,
            "language": "scala"
          },
          "persist_state": {
            "view": {
              "type": "details",
              "tableOptions": {},
              "chartOptions": {
                "chartType": "bar",
                "aggregationType": "count",
                "categoryFieldKeys": [
                  "0"
                ],
                "seriesFieldKeys": [
                  "0"
                ],
                "isStacked": false
              }
            }
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}